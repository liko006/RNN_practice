{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Reference\n",
    "\n",
    "https://github.com/tk-rusch/coRNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from logger import setup_logger\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hid = 128\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "embedding = 100\n",
    "lr = 6e-4\n",
    "delta = 5.4e-2\n",
    "gamma = 4.9\n",
    "epsilon = 4.8\n",
    "\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. prepare IMDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(bs,embedding_size):\n",
    "    text = data.Field(tokenize='spacy', include_lengths=True)\n",
    "    label = data.LabelField(dtype=torch.float)\n",
    "    train_data, test_data = datasets.IMDB.splits(text, label)\n",
    "    train_data, valid_data = train_data.split()\n",
    "\n",
    "    max_vocab_size = 25_000\n",
    "    text.build_vocab(train_data,\n",
    "                     max_size=max_vocab_size,\n",
    "                     vectors=\"glove.6B.\"+str(embedding_size)+\"d\",\n",
    "                     unk_init=torch.Tensor.normal_)\n",
    "    label.build_vocab(train_data)\n",
    "    train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits((train_data, valid_data, test_data),\n",
    "                                                                               batch_size=bs, sort=False)\n",
    "\n",
    "    return train_iterator, valid_iterator, test_iterator, text\n",
    "\n",
    "def zero_words_in_embedding(model, embedding_size, text, pad_idx):\n",
    "    pretrained_embeddings = text.vocab.vectors\n",
    "    model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "    UNK_IDX = text.vocab.stoi[text.unk_token]\n",
    "\n",
    "    model.embedding.weight.data[UNK_IDX] = torch.zeros(embedding_size)\n",
    "    model.embedding.weight.data[pad_idx] = torch.zeros(embedding_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build network model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) coRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class coRNN(nn.Module):\n",
    "    def __init__(self, n_inp, n_hid, dt, gamma, epsilon):\n",
    "        super(coRNN, self).__init__()\n",
    "        self.n_hid = n_hid\n",
    "        self.dt = dt\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.i2h = nn.Linear(n_inp, n_hid)\n",
    "        self.h2h = nn.Linear(n_hid+n_hid, n_hid, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hy = Variable(torch.zeros(x.size(1),self.n_hid)).to(device)\n",
    "        hz = Variable(torch.zeros(x.size(1),self.n_hid)).to(device)\n",
    "        inputs = self.i2h(x)\n",
    "        for t in range(x.size(0)):\n",
    "            hz = hz + self.dt * (torch.tanh(self.h2h(torch.cat((hz,hy),dim=1)) + inputs[t])\n",
    "                                          - self.gamma * hy - self.epsilon * hz)\n",
    "            hy = hy + self.dt * hz\n",
    "\n",
    "        return hy\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, pad_idx, dt, gamma, epsilon):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        self.rnn = coRNN(embedding_dim, hidden_dim, dt, gamma, epsilon).to(device)\n",
    "        self.readout = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text, text_lengths):\n",
    "        embedded = self.embedding(text)\n",
    "        hidden = self.rnn(embedded)\n",
    "        return self.readout(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. train / valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/torchtext/data/field.py:150: UserWarning: LabelField class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "## set up data iterators and dictonary:\n",
    "train_iterator, valid_iterator, test_iterator, text_field = get_data(batch_size, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inp = len(text_field.vocab)\n",
    "n_out = 1\n",
    "pad_idx = text_field.vocab.stoi[text_field.pad_token]\n",
    "\n",
    "model = RNNModel(n_inp, embedding, n_hid, n_out, pad_idx, delta, gamma, epsilon).to(device)\n",
    "\n",
    "## zero embedding for <unk_token> and <padding_token>:\n",
    "zero_words_in_embedding(model, embedding, text_field, pad_idx)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# accuracy fn\n",
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "# eval fn\n",
    "def evaluate(data_iterator):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_iterator):\n",
    "            \n",
    "            text, text_lengths = batch.text\n",
    "            text = text.to(device)\n",
    "            text_lengths = text_lengths.to(device)\n",
    "            label = batch.label.to(device)\n",
    "            \n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            loss = criterion(predictions, label)\n",
    "            acc = binary_accuracy(predictions, label)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "    return epoch_loss / len(data_iterator), epoch_acc / len(data_iterator)\n",
    "\n",
    "# train fn\n",
    "def train(epoch):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    with tqdm(total=len(train_iterator.dataset)) as progress_bar:\n",
    "        for i, batch in enumerate(train_iterator):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            text, text_lengths = batch.text\n",
    "            text = text.to(device)\n",
    "            text_lengths = text_lengths.to(device)\n",
    "            label = batch.label.to(device)\n",
    "            \n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            loss = criterion(predictions, label)\n",
    "            acc = binary_accuracy(predictions, label)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "            progress_bar.set_postfix(loss=(epoch_loss/(i+1)))\n",
    "            progress_bar.update(text_lengths.size(0))\n",
    "    \n",
    "#     logger.info(\"Epoch : {:d} | Lr: {:.6f} | Loss: {:.4f} | Cost Time: {}\".format(\n",
    "#                 epoch, optimizer.param_groups[0]['lr'], (epoch_loss / len(train_iterator)),\n",
    "#                 str(datetime.timedelta(seconds=int(time.time() - start_time)))))\n",
    "    \n",
    "    return epoch_loss / len(train_iterator), epoch_acc / len(train_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17500 [00:00<?, ?it/s]/opt/conda/lib/python3.6/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "100%|██████████| 17500/17500 [04:00<00:00, 74.05it/s, loss=0.693]\n",
      "  0%|          | 0/17500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Loss: 0.6933, Accuracy: 0.500\n",
      "\n",
      "Valid set: Loss: 0.6930, Accuracy: 0.504\n",
      "\n",
      "Test set: Loss: 0.6931, Accuracy: 0.501\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17500/17500 [03:55<00:00, 75.57it/s, loss=0.693]\n",
      "  0%|          | 0/17500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Loss: 0.6931, Accuracy: 0.496\n",
      "\n",
      "Valid set: Loss: 0.6930, Accuracy: 0.505\n",
      "\n",
      "Test set: Loss: 0.6930, Accuracy: 0.504\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17500/17500 [03:58<00:00, 77.98it/s, loss=0.693]\n",
      "  0%|          | 0/17500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Loss: 0.6928, Accuracy: 0.504\n",
      "\n",
      "Valid set: Loss: 0.6929, Accuracy: 0.500\n",
      "\n",
      "Test set: Loss: 0.6929, Accuracy: 0.502\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17500/17500 [03:57<00:00, 77.47it/s, loss=0.691]\n",
      "  0%|          | 0/17500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Loss: 0.6914, Accuracy: 0.502\n",
      "\n",
      "Valid set: Loss: 0.6421, Accuracy: 0.668\n",
      "\n",
      "Test set: Loss: 0.6497, Accuracy: 0.660\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17500/17500 [03:49<00:00, 69.99it/s, loss=0.546]\n",
      "  0%|          | 0/17500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Loss: 0.5462, Accuracy: 0.740\n",
      "\n",
      "Valid set: Loss: 0.4238, Accuracy: 0.822\n",
      "\n",
      "Test set: Loss: 0.4364, Accuracy: 0.811\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17500/17500 [03:55<00:00, 65.06it/s, loss=0.358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Loss: 0.3583, Accuracy: 0.859\n",
      "\n",
      "Valid set: Loss: 0.3764, Accuracy: 0.854\n",
      "\n",
      "Test set: Loss: 0.3996, Accuracy: 0.841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "    \n",
    "# set logger\n",
    "# logger = setup_logger(\"sentiment_analysis\", '/home/JinK/IMDB/runs/logs',\n",
    "#                       filename='{}_train_log.txt'.format(model.__class__.__name__), mode='a+')\n",
    "\n",
    "for epoch in range(6):\n",
    "    train_loss, train_acc = train(epoch)\n",
    "    eval_loss, eval_acc = evaluate(valid_iterator)\n",
    "    test_loss, test_acc = evaluate(test_iterator)\n",
    "    print('Train set: Loss: {:.4f}, Accuracy: {:.3f}\\n'.format(train_loss, train_acc))\n",
    "    print('Valid set: Loss: {:.4f}, Accuracy: {:.3f}\\n'.format(eval_loss, eval_acc))\n",
    "    print('Test set: Loss: {:.4f}, Accuracy: {:.3f}\\n'.format(test_loss, test_acc))\n",
    "\n",
    "    # save model after specified epochs\n",
    "#     if (epoch+1) % 25 == 0:\n",
    "#         print('saving model...')\n",
    "#         torch.save(model.state_dict(), f'models/{model.__class__.__name__}-e{epoch+1}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'models/{model.__class__.__name__}-e6_seed_fixed.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = RNNModel(n_inp, embedding, n_hid, n_out, pad_idx, delta, gamma, epsilon).to(device)\n",
    "model2.load_state_dict(torch.load(f'models/{model.__class__.__name__}-e12_test.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_t(data_iterator, model):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for i, batch in enumerate(data_iterator):\n",
    "\n",
    "        text, text_lengths = batch.text\n",
    "        text = text.to(device)\n",
    "        text_lengths = text_lengths.to(device)\n",
    "        label = batch.label.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            \n",
    "        loss = criterion(predictions, label)\n",
    "        acc = binary_accuracy(predictions, label)\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "            \n",
    "    return epoch_loss / len(data_iterator), epoch_acc / len(data_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Loss: 2.0665, Accuracy: 0.446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_t(test_iterator, model2)\n",
    "print('Test set: Loss: {:.4f}, Accuracy: {:.3f}\\n'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'models/{model.__class__.__name__}-e12_test.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 12 epochs, Test set Loss : 0.4732 , Acc : 0.863 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = RNNModel(n_inp, embedding, n_hid, n_out, pad_idx, delta, gamma, epsilon).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_state_dict(torch.load(f'models/{model.__class__.__name__}-e12_test.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Loss: 0.4732, Accuracy: 0.863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(test_iterator)\n",
    "print('Test set: Loss: {:.4f}, Accuracy: {:.3f}\\n'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = RNNModel(n_inp, embedding, n_hid, n_out, pad_idx, delta, gamma, epsilon).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_t(data_iterator, model):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for i, batch in enumerate(data_iterator):\n",
    "\n",
    "        text, text_lengths = batch.text\n",
    "        text = text.to(device)\n",
    "        text_lengths = text_lengths.to(device)\n",
    "        label = batch.label.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            \n",
    "        loss = criterion(predictions, label)\n",
    "        acc = binary_accuracy(predictions, label)\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "            \n",
    "    return epoch_loss / len(data_iterator), epoch_acc / len(data_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.load_state_dict(torch.load(f'models/{model.__class__.__name__}-e100.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Loss: 1.6481, Accuracy: 0.540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_t(test_iterator, model2)\n",
    "print('Test set: Loss: {:.4f}, Accuracy: {:.3f}\\n'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Loss: 2.7998, Accuracy: 0.524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_t(test_iterator, model3)\n",
    "print('Test set: Loss: {:.4f}, Accuracy: {:.3f}\\n'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Loss: 2.0971, Accuracy: 0.545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate_t(test_iterator, model3)\n",
    "print('Test set: Loss: {:.4f}, Accuracy: {:.3f}\\n'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. load / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up data iterators and dictonary:\n",
    "train_iterator, valid_iterator, test_iterator, text_field = get_data(batch_size, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inp = len(text_field.vocab)\n",
    "n_out = 1\n",
    "pad_idx = text_field.vocab.stoi[text_field.pad_token]\n",
    "\n",
    "model = RNNModel(n_inp, embedding, n_hid, n_out, pad_idx, delta, gamma, epsilon).to(device)\n",
    "\n",
    "## zero embedding for <unk_token> and <padding_token>:\n",
    "# zero_words_in_embedding(model, embedding, text_field, pad_idx)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# accuracy fn\n",
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "# eval fn\n",
    "def evaluate(data_iterator):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for i, batch in enumerate(data_iterator):\n",
    "\n",
    "        text, text_lengths = batch.text\n",
    "        text = text.to(device)\n",
    "        text_lengths = text_lengths.to(device)\n",
    "        label = batch.label.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            \n",
    "        loss = criterion(predictions, label)\n",
    "        acc = binary_accuracy(predictions, label)\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "            \n",
    "    return epoch_loss / len(data_iterator), epoch_acc / len(data_iterator)\n",
    "\n",
    "model.load_state_dict(torch.load(f'models/{model.__class__.__name__}-e100.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# set logger\n",
    "logger = setup_logger(\"sentiment_analysis\", '/home/JinK/IMDb/runs/logs',\n",
    "                      filename='{}_test_acc_log.txt'.format(model.__class__.__name__), mode='a+')\n",
    "\n",
    "\n",
    "test_loss, test_acc = evaluate(test_iterator)\n",
    "print('Test set: Loss: {:.4f}, Accuracy: {:.3f}\\n'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
