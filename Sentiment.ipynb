{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://wikidocs.net/60314\n",
    "\n",
    "https://wikidocs.net/64904"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torchtext\n",
    "from torchtext import data, datasets\n",
    "from torchtext.vocab import GloVe\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hid = 128\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "embedding = 300\n",
    "lr = 6e-4\n",
    "\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hid = 128\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "embedding = 100\n",
    "lr = 6e-4\n",
    "delta = 5.4e-2\n",
    "gamma = 4.9\n",
    "epsilon = 4.8\n",
    "\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 30002\n",
      "클래스의 개수 : 2\n",
      "임베딩 벡터의 개수와 차원 : torch.Size([30002, 300]) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "TEXT = torchtext.data.Field(sequential=True, batch_first=True, lower=True)\n",
    "LABEL = torchtext.data.Field(sequential=False, batch_first=True)\n",
    "\n",
    "trainset, testset = datasets.IMDB.splits(TEXT, LABEL)\n",
    "\n",
    "TEXT.build_vocab(trainset, vectors=GloVe(name='6B', dim=300), max_size=30000, min_freq=5)\n",
    "LABEL.build_vocab(trainset)\n",
    "\n",
    "vocab_size = len(TEXT.vocab)\n",
    "n_classes = 2\n",
    "\n",
    "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
    "print('클래스의 개수 : {}'.format(n_classes))\n",
    "print('임베딩 벡터의 개수와 차원 : {} '.format(TEXT.vocab.vectors.shape))\n",
    "\n",
    "trainset, valset = trainset.split(split_ratio=0.8)\n",
    "\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
    "        (trainset, valset, testset), batch_size=batch_size,\n",
    "        shuffle=True, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Build Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. GRU type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
    "        super(GRU, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
    "#         self.embedding_layer = nn.Embedding.from_pretrained(TEXT.vocab.vectors, freeze=False)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.gru = nn.GRU(embed_dim, self.hidden_dim, num_layers=self.n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(self.hidden_dim, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        h0 = self._init_state(batch_size=x.size(0)) # 첫번째 hidden state를 0벡터로 초기화\n",
    "        x, _ = self.gru(x, h0)  # GRU의 리턴값은 (배치 크기, 시퀀스 길이, hidden state의 크기)\n",
    "        ht = x[:, -1, :]  # 마지막 time-step의 hidden state만 가져옴\n",
    "        out = self.dropout(ht)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "    def _init_state(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Embedding: 1-1                         9,000,600\n",
      "├─Dropout: 1-2                           --\n",
      "├─GRU: 1-3                               462,336\n",
      "├─Linear: 1-4                            258\n",
      "=================================================================\n",
      "Total params: 9,463,194\n",
      "Trainable params: 9,463,194\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "model = GRU(4, n_hid, vocab_size, embedding, n_classes).to(device)\n",
    "print(summary(model, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. LSTM type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, n_vocab, hidden_dim, n_layers, embed_dim, n_classes, dropout_p=0.2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "#         self.embed = nn.Embedding(n_vocab, embed_dim)\n",
    "        self.embedding_layer = nn.Embedding.from_pretrained(TEXT.vocab.vectors, freeze=False)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.lstm = nn.LSTM(embed_dim, self.hidden_dim, num_layers=self.n_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(self.hidden_dim*2, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding_layer(x)\n",
    "#         (h0, c0) = self._init_state(batch_size=x.size(0))\n",
    "        x, _ = self.lstm(x)\n",
    "        ht = x[:,-1,:]\n",
    "        out = self.dropout(ht)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "    def _init_state(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Embedding: 1-1                         9,000,600\n",
      "├─Dropout: 1-2                           --\n",
      "├─LSTM: 1-3                              1,626,112\n",
      "├─Linear: 1-4                            514\n",
      "=================================================================\n",
      "Total params: 10,627,226\n",
      "Trainable params: 10,627,226\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "model = LSTM(vocab_size, n_hid, 4, embedding, n_classes).to(device)\n",
    "print(summary(model, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Set Optim, loss, Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def acc(output, target):\n",
    "    return (output.max(1)[1].view(target.size()).data == target.data).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Train model / save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, tran_iter):\n",
    "    \n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.train()\n",
    "    with tqdm(total=len(train_iter.dataset)) as progress_bar: \n",
    "        for i, batch in enumerate(train_iter):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            text = batch.text.to(device)\n",
    "            target = batch.label.to(device)\n",
    "            target.data.sub_(1) # 레이블 값을 0과 1로 변환\n",
    "            print(text.shape)\n",
    "            output = model(text)\n",
    "            print(output.shape)\n",
    "            print(target.shape)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_acc += acc(output,target)\n",
    "            \n",
    "            progress_bar.set_postfix(loss=(train_loss/(i+1)))\n",
    "            progress_bar.update(text.size(0))\n",
    "\n",
    "    return train_loss / len(train_iter.dataset), train_acc / len(train_iter.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, val_iter):\n",
    "    \n",
    "    t_acc, t_loss = 0, 0\n",
    "    model.eval()\n",
    "    for batch in val_iter:\n",
    "        text = batch.text.to(device)\n",
    "        target = batch.label.to(device)\n",
    "        target.data.sub_(1) # 레이블 값을 0과 1로 변환\n",
    "        \n",
    "        output = model(text)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        t_loss += loss.item()\n",
    "        t_acc += acc(output, target)\n",
    "    \n",
    "    return t_loss / len(val_iter.dataset), t_acc / len(val_iter.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = None\n",
    "for e in range(30):\n",
    "    train_loss, train_acc = train(model, optimizer, train_iter)\n",
    "    val_loss, val_acc = evaluate(model, val_iter)\n",
    "\n",
    "    print(f\"[Epoch: %d] train loss : %.4f | train acc : %.4f | val loss : %.4f | val acc : %.4f\" \n",
    "          % (e+1, train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        if not os.path.isdir(\"models\"):\n",
    "            os.makedirs(\"models\")\n",
    "        torch.save(model.state_dict(), f'models/{model.__class__.__name__}_4-layer-e{e+1}.pth')\n",
    "        best_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'models/{model.__class__.__name__}_4-layer-e{e+1}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Load and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def acc(output, target):\n",
    "    return (output.max(1)[1].view(target.size()).data == target.data).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GRU(4, n_hid, vocab_size, embedding, n_classes).to(device)\n",
    "model.load_state_dict(torch.load('models/GRU_h128_4-layer-e50.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LSTM(vocab_size, n_hid, 4, embedding, n_classes).to(device)\n",
    "model2.load_state_dict(torch.load('models/LSTM_h128_4-layer-e23.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 오차: 0.0094 | 테스트 정확도: 0.8370\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_iter)\n",
    "print('테스트 오차: %.4f | 테스트 정확도: %.4f' % (test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 오차: 0.0028 | 테스트 정확도: 0.8743\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model2, test_iter)\n",
    "print('테스트 오차: %.4f | 테스트 정확도: %.4f' % (test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LSTM(vocab_size, n_hid, 1, embedding, n_classes).to(device)\n",
    "model2.load_state_dict(torch.load('models/LSTM_h256_pre-embed-e45.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 오차: 0.0026 | 테스트 정확도: 0.8580\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model2, test_iter)\n",
    "print('테스트 오차: %.4f | 테스트 정확도: %.4f' % (test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = LSTM(vocab_size, 256, 1, embedding, n_classes).to(device)\n",
    "model3.load_state_dict(torch.load('models/LSTM_h256-e22.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 오차: 0.0044 | 테스트 정확도: 0.8645\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model3, test_iter)\n",
    "print('테스트 오차: %.4f | 테스트 정확도: %.4f' % (test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 오차: 0.0026 | 테스트 정확도: 0.8585\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model3, test_iter)\n",
    "print('테스트 오차: %.4f | 테스트 정확도: %.4f' % (test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 오차: 0.0035 | 테스트 정확도: 0.8056\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model3, test_iter)\n",
    "print('테스트 오차: %.4f | 테스트 정확도: %.4f' % (test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM (Bidirectional, 4-layers stacked, 128 Hids, Ep 23) -> Test Acc : 87.43%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
